/home/dongrui/anaconda3/envs/dr/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Namespace(device='cuda:0', seed=2023, dataset='PTC_FR', in_size=19, num_classes=2, model_name='fusion_tm', fusion_type='early', gcn_channels=3, gcn_hidden=128, gcn_layers=4, gcn_dropout=0.1, trans_num_layers=4, input_node_dim=19, hidden_node_dim=32, input_edge_dim=4, hidden_edge_dim=32, ouput_dim=None, n_heads=4, max_in_degree=5, max_out_degree=5, max_path_distance=5, hidden_dim=128, num_layers=4, num_features=19, num_heads=8, dropout=0.1, pos_encoding='gcn', att_dropout=0.1, d_k=64, d_v=64, pos_embed_type='s', alpha=0.6, num_fusion_layers=6, eta=0.5, ffn_dim=128, num_trans_layers=3, lam1=0.2, lam2=0.2, theta1=0.15, theta2=0.4, theta3=0.4, gamma=0.7, patience=500, loss_log=2, folds=10, lr=1e-05, weight_decay=5e-05, batch_size=128, epoches=1000, output_dim=2)
Running 0 times
/home/dongrui/anaconda3/envs/dr/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Fold: 0
Epoch: 000 train_loss: 0.005235 val_loss: 0.513010 val_acc: 0.514286 test_loss: 0.442605 test_acc: 0.638889
Epoch: 010 train_loss: 0.004802 val_loss: 0.521724 val_acc: 0.485714 test_loss: 0.429732 test_acc: 0.750000
Epoch: 020 train_loss: 0.004704 val_loss: 0.513265 val_acc: 0.514286 test_loss: 0.437178 test_acc: 0.777778
Epoch: 030 train_loss: 0.004541 val_loss: 0.518690 val_acc: 0.514286 test_loss: 0.430945 test_acc: 0.750000
Epoch: 040 train_loss: 0.004489 val_loss: 0.517307 val_acc: 0.571429 test_loss: 0.455357 test_acc: 0.583333
Epoch: 050 train_loss: 0.004554 val_loss: 0.521107 val_acc: 0.600000 test_loss: 0.439483 test_acc: 0.611111
Epoch: 060 train_loss: 0.004282 val_loss: 0.515045 val_acc: 0.600000 test_loss: 0.441693 test_acc: 0.583333
Epoch: 070 train_loss: 0.004268 val_loss: 0.572572 val_acc: 0.571429 test_loss: 0.435812 test_acc: 0.750000
Epoch: 080 train_loss: 0.004391 val_loss: 0.541916 val_acc: 0.600000 test_loss: 0.448890 test_acc: 0.611111
Epoch: 090 train_loss: 0.004260 val_loss: 0.540036 val_acc: 0.657143 test_loss: 0.445978 test_acc: 0.694444
Epoch: 100 train_loss: 0.004150 val_loss: 0.534874 val_acc: 0.685714 test_loss: 0.446904 test_acc: 0.638889
Epoch: 110 train_loss: 0.004120 val_loss: 0.559731 val_acc: 0.657143 test_loss: 0.448714 test_acc: 0.694444
Epoch: 120 train_loss: 0.003887 val_loss: 0.561134 val_acc: 0.628571 test_loss: 0.483615 test_acc: 0.638889
Epoch: 130 train_loss: 0.004030 val_loss: 0.569458 val_acc: 0.657143 test_loss: 0.481219 test_acc: 0.638889
